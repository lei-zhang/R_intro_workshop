g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.25, height=0.25, size=5, colour='skyblue', alpha=0.95)
g1 <- g1 + myconfig + labs(x = 'IQ', y = 'Choice accuracy')
# add the regression line
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.25, height=0.25, size=5, colour='skyblue', alpha=0.95)
g1 <- g1 + myconfig + labs(x = 'IQ', y = 'Choice accuracy')
# add the regression line
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.25, height=0.25, size=5, colour='skyblue', alpha=0.95)
g1 <- g1 + myconfig + labs(x = 'IQ', y = 'Choice accuracy')
# add the regression line
g1
df
df
df
fd
df
df
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.25, height=0.25, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.25, height=0.25, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.25, height=0.25, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.25, height=0.25, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.25, height=0.25, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.25, height=0.25, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.25, height=0.25, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.01, height=0.01, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.01, height=0.01, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.01, height=0.01, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.01, height=0.01, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.01, height=0.01, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1 <- g1 + myconfig + labs(x = 'IQ', y = 'Choice accuracy')
# add the regression line
g1 <- g1 + geom_smooth(method = "lm", se = T, colour='skyblue3')
g1
ggsave(plot = g1, "_plots/scatter.png", width = 4, height = 3, type = "cairo-png", units = "in")
ggsave(plot = g1, "_plots/scatter.png", width = 6, height = 4, type = "cairo-png", units = "in")
g1 <- ggplot(df, aes(age,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1 <- g1 + myconfig + labs(x = 'IQ', y = 'Choice accuracy (%)')
# add the regression line
g1 <- g1 + geom_smooth(method = "lm", se = T, colour='skyblue3')
g1
ggsave(plot = g1, "_plots/scatter.png", width = 4, height = 3, type = "cairo-png", units = "in")
g1 <- ggplot(df, aes(Age,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1 <- g1 + myconfig + labs(x = 'IQ', y = 'Choice accuracy (%)')
# add the regression line
g1 <- g1 + geom_smooth(method = "lm", se = T, colour='skyblue3')
g1
ggsave(plot = g1, "_plots/scatter.png", width = 4, height = 3, type = "cairo-png", units = "in")
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1 <- g1 + myconfig + labs(x = 'IQ', y = 'Choice accuracy (%)')
# add the regression line
g1 <- g1 + geom_smooth(method = "lm", se = T, colour='skyblue3')
g1
ggsave(plot = g1, "_plots/scatter.png", width = 4, height = 3, type = "cairo-png", units = "in")
ns = 10
data_dir = '_data/RL_raw_data'
rawdata = c();
for (s in 1:ns) {
sub_file = file.path(data_dir, sprintf('sub%02i/raw_data_sub%02i.txt',s,s))
sub_data = read.table(sub_file, header = T, sep = ",")
rawdata = rbind(rawdata, sub_data)
}
rawdata = rawdata[complete.cases(rawdata),]
rawdata$accuracy = (rawdata$choice == rawdata$correct) * 1.0
acc_mean = aggregate(rawdata$accuracy, by = list(rawdata$subjID), mean)[,2]
load('_data/RL_descriptive.RData')
descriptive$acc = acc_mean
df = descriptive
# =============================================================================
#### basic stats ####
# =============================================================================
# one sample t-test , to test if 'acc' is above chance level
t.test(acc_mean, mu = 0.5)
# simple correlation, to test if IQ is correlated with acc
cor.test(df$IQ, df$acc)
# =============================================================================
#### plot the scatter and the regression line ####
# =============================================================================
myconfig <- theme_bw(base_size = 20) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank() )
# scatter plot
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1 <- g1 + myconfig + labs(x = 'IQ', y = 'Choice accuracy (%)')
# add the regression line
g1 <- g1 + geom_smooth(method = "lm", se = T, colour='skyblue3')
g1
library(ggplot2)
myconfig <- theme_bw(base_size = 20) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank() )
# scatter plot
g1 <- ggplot(df, aes(IQ,acc))
g1 <- g1 + geom_jitter(width=0.0, height=0.0, size=5, colour='skyblue', alpha=0.95)
g1 <- g1 + myconfig + labs(x = 'IQ', y = 'Choice accuracy (%)')
# add the regression line
g1 <- g1 + geom_smooth(method = "lm", se = T, colour='skyblue3')
g1
fit = lm(acc ~ IQ, data = df)
summary(fit)
cor.test(df$IQ, df$acc)
.8631401 ^ 2
fit1 = lm(acc ~ IQ, data = df)
fit2 = lm(acc ~ IQ + Age, data = df)
fit3 = lm(acc ~ IQ * Age, data = df)
anova(fit1, fit2, fit3)
AIC(fit1, fit2, fit3)
sumary(fit2)
summary(fit2)
summary(fit3)
s = summary(fit3)
s
s$r.squared
fit1 = lm(acc ~ IQ, data = df)
fit2 = lm(acc ~ Age, data = df)
fit3 = lm(acc ~ IQ + Age, data = df)
fit4 = lm(acc ~ IQ * Age, data = df) # IQ + Age + IQ:Age
anove(fit1, fit2, fit3, fit4 )
anova(fit1, fit2, fit3, fit4 )
AIC(fit1, fit2, fit3, fit4 )
AIC(fit1, fit2, fit3, fit4 )[,2]
round(AIC(fit1, fit2, fit3, fit4 )[,2],2)
0.02791^2
summary(fit1)$r.squared
summary(fit2)$r.squared
summary(fit3)$r.squared
summary(fit4)$r.squared
L = list(fit1, fit2, fit3, fit4 )
sapply(L, function(x){summary(x)$r.squared})
round(summary(fit1)$r.squared,2)
round(summary(fit2)$r.squared,2)
round(summary(fit3)$r.squared,2)
round(summary(fit4)$r.squared,2)
sapply(L, function(x){round(summary(x)$r.squared,2)})
sapply(L, function(x){round(summary(x)$adj.r.squared,2)})
fit4
cor.test(df$IQ, df$Age)
library(MASS)
dim(UScrime)
strUScrime)
str(UScrime)
? UScrime
library(MASS)
str(UScrime)
# U1 unemployment rate of urban males 14–24.
# U2 unemployment rate of urban males 35–39.
t.test(UScrime$U1, UScrime$U2, paired=TRUE)
hist(UScrime$U1 -  UScrime$U2)
library(multcomp)
cholesterol
unique(cholesterol$trt)
aggregate(response, by=list(trt), FUN=mean)
aggregate(cholesterol$response, by=list(cholesterol$trt), FUN=mean)
fit <- aov(response ~ trt)
summary(fit)
fit <- aov(response ~ trt, data = cholesterol)
summary(fit)
summary(aov(response ~ trt, data = cholesterol))
summary(lm(response ~ trt, data = cholesterol))
install.packages('BEST')
library(BEST)
install.packages('BayesianFirstAid')
install.packages("devtools")
devtools::install_github("rasmusab/bayesian_first_aid")
library(glue)
dl = list(N = dim(UScrime)[1], y1 = UScrime$U1, y2 = UScrime$U2, mu_y=mean(c(UScrime$U1,UScrime$U2)))
rstan::rstan_options(auto_write = TRUE)
# =============================================================================
#### Exercise VII ####
# =============================================================================
library(MASS)
dl = list(N = dim(UScrime)[1], y1 = UScrime$U1, y2 = UScrime$U2, mu_y=mean(c(UScrime$U1,UScrime$U2)))
rstan::rstan_options(auto_write = TRUE)
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
rstan:::rstudio_stanc("_scripts/bayes_2mean_ttest_DBDA.stan")
rstan:::rstudio_stanc("_scripts/bayes_2mean_ttest_DBDA.stan")
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
# =============================================================================
#### Exercise VII ####
# =============================================================================
library(MASS)
dl = list(N = dim(UScrime)[1], y1 = UScrime$U1, y2 = UScrime$U2, mu_y=mean(c(UScrime$U1,UScrime$U2)))
rstan::rstan_options(auto_write = TRUE)
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
library(rstan)
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
f = rstan::stan('_scripts/bayes_2mean_ttest_DBDA.stan', data = dl, cores=4,iter = 4000)
sd(c(UScrime$U1,UScrime$U2))
dl = list(N = dim(UScrime)[1], y1 = UScrime$U1, y2 = UScrime$U2,
mu_y=mean(c(UScrime$U1,UScrime$U2)), sd_y=sd(c(UScrime$U1,UScrime$U2)) )
f = rstan::stan('_scripts/bayes_2mean_ttest_DBDA.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
rstan:::rstudio_stanc("_scripts/bayes_2mean_ttest.stan")
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
?seq
x
x = seq(from=0.01, to = 10, by = 0.01)
x
?pexp
b = 1/29
b
y = b *  exp(−b * x)
plot(x,y, type='l')
b=1
b = 1; y = b *  exp(-b * x); plot(x,y, type='l')
b = 2; y = b *  exp(-b * x); plot(x,y, type='l')
b = 3; y = b *  exp(-b * x); plot(x,y, type='l')
b = 0.5; y = b *  exp(-b * x); plot(x,y, type='l')
b = 0.01; y = b *  exp(-b * x); plot(x,y, type='l')
x = seq(from=-10, to = 10, by = 0.01)
b = 0.01; y = exp(pnorm(0,b)); plot(x,y, type='l')
b = 0.01; y = exp(pnorm(x,0,b)); plot(x,y, type='l')
b = 1; y = exp(pnorm(x,0,b)); plot(x,y, type='l')
pnorm(x,0,b)
exp(0.01)
exp(0)
exp(-0.01)
?dnorm
b = 1; y = exp(rnorm(1000,0,b)); plot(x,y, type='l')
b = 1; y = exp(rnorm(1000,0,b)); plot(1000,y, type='l')
y = exp(rnorm(1000,0,b))
b = 1; y = exp(rnorm(1000,0,b)); plot(1000,y, type='l')
b = 1; y = exp(rnorm(1000,0,b)); plot(1:1000,y, type='l')
b = 1; y = exp(rnorm(1000,0,b)); hist(1:1000,y, type='l')
b = 1; y = exp(rnorm(1000,0,b)); hist(1:1000,)
b = 1; y = exp(rnorm(1000,0,b)); hist(1:1000,y)
b = 1; y = exp(rnorm(1000,0,b)); hist(y)
b = .1; y = exp(rnorm(1000,0,b)); hist(y)
b = 1; y = exp(rnorm(1000,0,b)); hist(y)
b = .1; y = exp(rnorm(1000,0,b)); hist(y)
b = 2; y = exp(rnorm(1000,0,b)); hist(y)
b = 1.5; y = exp(rnorm(1000,0,b)); hist(y)
?hist
b = 1.5; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1)
b = 1.5; y = exp(rnorm(1000,0,b)); hist(y, breaks = 2)
b = 1.5; y = exp(rnorm(1000,0,b)); hist(y, breaks = 100)
b = 1.5; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 1; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 0.5; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 0.9; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 0.8; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = `; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 1; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 1; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 1; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 1; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 1; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 1; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = .5; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 1; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 1; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
b = 2; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
rstan:::rstudio_stanc("_scripts/bayes_2mean_ttest.stan")
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
b = .99; y = exp(rnorm(1000,0,b)); hist(y, breaks = 1000)
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
f = rstan::stan('_scripts/bayes_2mean_ttest.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
f = rstan::stan('_scripts/bayes_2mean_ttest_DBDA.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu')$mu
mean(mu[,1] - mu[,2])
hBayesDM::plotHDI(mu[,1]-mu[,2])
dl = list(N = dim(UScrime)[1], y1 = UScrime$U1, y2 = UScrime$U2,
mu_y=mean(c(UScrime$U1,UScrime$U2)), sd_y=sd(c(UScrime$U1,UScrime$U2)) )
rstan::rstan_options(auto_write = TRUE)
f = rstan::stan('_scripts/bayes_2mean_ttest_DBDA.stan', data = dl, cores=4,iter = 4000)
mu = extract(f, pars='mu_diff')$mu
mean(mu_diff)
mu = extract(f, pars='mu_diff')$mu_diff
mean(mu_diff)
hBayesDM::plotHDI(mu_diff)
f@model_pars
mu = extract(f, pars='mu_diff')$mu_diff
mu_diff = extract(f, pars='mu_diff')$mu_diff
mean(mu_diff)
hBayesDM::plotHDI(mu_diff)
g1 = stan_plot(f, pars = 'mu_diff', ci_level=.95,outer_level=.99,point_est='mean',show_density=F, fill_color='skyblue')
g1
g1 = stan_plot(f, pars = 'mu_diff', ci_level=.95,outer_level=.99,point_est='mean',show_density=T, fill_color='skyblue')
g1
g1 = g1+coord_flip()+ theme_classic()
g1
g1 = g1 + theme_classic()
g1 = stan_plot(f, pars = 'mu_diff', ci_level=.95,outer_level=.99,point_est='mean',show_density=T, fill_color='skyblue')
g1 = g1 + theme_classic()
g1 = stan_plot(f, pars = 'mu_diff', ci_level=.95,outer_level=.99,point_est='mean',show_density=T, fill_color='skyblue')
g1 = g1 + theme_classic()
g1 = g1 + labs(title="",y="",x=expression(mu))
g1
g1 = stan_plot(f, pars = 'mu_diff', ci_level=.95,outer_level=.99,point_est='mean',show_density=T, fill_color='skyblue')
g1 = g1 + theme_classic()
g1 = g1 + labs(title="",y="",x=expression(mu1 - mu2))
g1
g = hBayesDM::plotHDI(mu_diff)
g
g + labs(x="")
g + labs(x=expression(mu['1']))
g + labs(x=paste(expression(mu['1']), expression(mu['2'])))
g + labs(x=expression(mu['1'] - mu['2']))
myconfig <- theme_bw(base_size = 20) +
theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
panel.background = element_blank() )
g = g + labs(x=expression(mu['1'] - mu['2'])) + myconfig
g
g + geom_histogram(col = 'black', fill = 'red')
g + geom_histogram(col = 'black', fill = 'red', binwidth = 5)
g + geom_histogram(col = 'black', fill = 'red', binwidth = 50)
g + geom_histogram(col = 'black', fill = 'red', binwidth = 1)
g + geom_histogram(col = 'black', fill = 'red', binwidth = 2)
g + geom_histogram(col = 'black', fill = 'red', binwidth = 0.1)
g + geom_histogram(col = 'black', fill = 'red', binwidth = 3)
g + geom_histogram(col = 'black', fill = 'red', binwidth = 2)
g + geom_histogram(col = 'black', fill = 'red', binwidth = 1)
g + geom_histogram(col = 'black', fill = 'skyblue', binwidth = 1)
g = hBayesDM::plotHDI(mu_diff)
g
g = g + labs(x=expression(mu['1'] - mu['2'])) + myconfig
g
ggsave(plot = g, "_plots/bayes_ttest.png", width = 4, height = 3, type = "cairo-png", units = "in")
mean(mu_diff)
g = hBayesDM::plotHDI(mu_diff)
UScrime$U1
UScrime$U2
UScrime$U1
UScrime$U2
install.packages('BayesFactor')
library(MASS)
bf = ttestBF(x = UScrime$U1, x = UScrime$U2, paired = T)
(BayesFactor)
#------------------------------------------------------------------------------
# Calculate Bayes Factor
library(BayesFactor)
bf = ttestBF(x = UScrime$U1, x = UScrime$U2, paired = T)
bf = ttestBF(x = UScrime$U1, y = UScrime$U2, paired = T)
bf
data(sleep)
ttestBF(x = sleep$extra[1:10],y=sleep$extra[11:20], paired=TRUE)
t.test(x = sleep$extra[1:10],y=sleep$extra[11:20], paired=TRUE)
t.test(x = UScrime$U1, y = UScrime$U2, paired = T)
ttestBF(x = UScrime$U2, y = UScrime$U1, paired = T)
t.test(x = sleep$extra[1:10],y=sleep$extra[11:20], paired=TRUE)
ttestBF(x = sleep$extra[1:10],y=sleep$extra[11:20], paired=TRUE)
exp
exp(1)
exp(2)
x  = 3
x
(x  = 3)
rm(list = ls())
x =3
X
X  = 3
c (1,3,-2)
x = c (1,3,-2)
x
x
sum(x)
mean(x)
range(x)
mix(x)
min(x)
max(x)
summary(x)
= c(1,3,4,6,8)
x= c(1,3,4,6,8)
y = c(2,3,5,7,9)
y =                     c(2,3,5,7,9)
y
x
y
cor(x,y)
cor.test(x,y)
cov(x,y)
x
y
dim(x)
length(x)
class(x)
length(y)
x
y
cbind(x,y)
rbind(x,y)
cbind(t(x),t(y))
t =3
t
cbind(t(x),t(y))
x * y
x - y
x
x = c(x, 4,6)
x
y
rbind(x,y)
cbind(x,y)
if ( length(x) == length(y) ) {
vector_new = cbind(x, y)
}
length(x) == length(y)
if ( length(x) == length(y) )
{ vector_new = cbind(x, y) }
if ( length(x) == length(y) ) {
vector_new = cbind(x, y)
} else {
warning('dim does not match')
}
getwd()
x = c(4,6)
x
ls()
? mean
x <- c(0:10, 50)
xm <- mean(x)
c(xm, mean(x, trim = 0.10))
x
x 1 = x
x1 = x
x2 = x
rm(list = ls())
ls()
rm(list = ls())
q()
